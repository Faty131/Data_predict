#!/usr/bin/env python3
"""
Script de modÃ©lisation prÃ©dictive pour l'analyse des retards des transports en commun
ExÃ©cute directement le code de modÃ©lisation sans notebook
"""

import sys
import os
import warnings
warnings.filterwarnings('ignore')

# Configuration matplotlib pour Ã©viter les erreurs GUI
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, f1_score, roc_auc_score
import xgboost as xgb
import joblib

# Configuration des visualisations
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
pd.set_option('display.max_columns', 50)
pd.set_option('display.width', 1000)

# CrÃ©ation des dossiers nÃ©cessaires
os.makedirs("./models", exist_ok=True)
os.makedirs("./results", exist_ok=True)
os.makedirs("./reports", exist_ok=True)

print("âœ… Configuration terminÃ©e")

# Chargement des donnÃ©es prÃ©parÃ©es (issues des notebooks prÃ©cÃ©dents)
print("ğŸ“¥ Chargement des donnÃ©es prÃ©parÃ©es...")
df = pd.read_csv("./data/processed/clean_data.csv")
print(f"ğŸ“Š Shape: {df.shape}")
print(f"ğŸ¯ Colonnes: {list(df.columns)}")

# AperÃ§u rapide
print("\nğŸ“‹ AperÃ§u des donnÃ©es:")
print(df.head())

# PrÃ©paration des donnÃ©es pour la modÃ©lisation
print("ğŸ”§ PrÃ©paration des donnÃ©es pour la modÃ©lisation...")

# Encodage des variables catÃ©gorielles si nÃ©cessaire
categorical_cols = ['TransportType', 'Line', 'Status', 'IncidentCause']
le = LabelEncoder()

for col in categorical_cols:
    if col in df.columns:
        df[col + '_encoded'] = le.fit_transform(df[col].astype(str))

# SÃ©lection des features (adapter selon les features crÃ©Ã©es dans le notebook de feature engineering)
feature_cols = [col for col in df.columns if col.endswith('_encoded') or col in ['delay_minutes']]
if 'hour' in df.columns:
    feature_cols.append('hour')
if 'day_of_week' in df.columns:
    feature_cols.append('day_of_week')

X = df[feature_cols].drop('delay_minutes', axis=1)
y = df['delay_minutes']

print(f"ğŸ“ Features sÃ©lectionnÃ©es: {list(X.columns)}")
print(f"ğŸ¯ Target: delay_minutes")
print(f"ğŸ“Š Shape: {X.shape}")

# Split des donnÃ©es
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Train shape: {X_train.shape}")
print(f"Test shape: {X_test.shape}")

# ModÃ¨les Ã  tester
models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
    'XGBoost': xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
}

results = {}

for name, model in models.items():
    print(f"\nğŸƒ EntraÃ®nement de {name}...")

    # EntraÃ®nement
    model.fit(X_train, y_train)

    # PrÃ©dictions
    y_pred = model.predict(X_test)

    # MÃ©triques
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    results[name] = {
        'RMSE': rmse,
        'MAE': mae,
        'RÂ²': r2
    }

    print(f"  â€¢ RMSE: {rmse:.2f}")
    print(f"  â€¢ MAE: {mae:.2f}")
    print(f"  â€¢ RÂ²: {r2:.3f}")

# Sauvegarde du meilleur modÃ¨le
best_model_name = max(results, key=lambda x: results[x]['RÂ²'])
best_model = models[best_model_name]
joblib.dump(best_model, f"./models/{best_model_name.lower().replace(' ', '_')}.pkl")

print(f"\nğŸ’¾ Meilleur modÃ¨le sauvegardÃ©: {best_model_name}")

# Comparaison des modÃ¨les
results_df = pd.DataFrame(results).T
print("\nğŸ“Š Comparaison des ModÃ¨les:")
print(results_df)

# Visualisation
results_df.plot(kind='bar', figsize=(10, 6))
plt.title('Comparaison des MÃ©triques des ModÃ¨les')
plt.ylabel('Valeur')
plt.xticks(rotation=45)
plt.legend(loc='upper left', bbox_to_anchor=(1, 1))
plt.tight_layout()
plt.savefig("./results/model_comparison.png")
# plt.show()  # CommentÃ© pour Ã©viter l'erreur GUI

# Analyse des features importantes (pour Random Forest)
if 'Random Forest' in models:
    rf_model = models['Random Forest']
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': rf_model.feature_importances_
    }).sort_values('importance', ascending=False)

    plt.figure(figsize=(10, 6))
    sns.barplot(x='importance', y='feature', data=feature_importance.head(10))
    plt.title('Top 10 Features Importantes (Random Forest)')
    plt.savefig("./results/feature_importance.png")
    # plt.show()  # CommentÃ© pour Ã©viter l'erreur GUI

    print("\nğŸ” Top 5 features importantes:")
    print(feature_importance.head(5))

# Validation croisÃ©e pour le meilleur modÃ¨le
print("ğŸ”„ Validation croisÃ©e du meilleur modÃ¨le...")

cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='neg_mean_squared_error')
cv_rmse_scores = np.sqrt(-cv_scores)

print(f"ğŸ“Š Scores RMSE en validation croisÃ©e: {cv_rmse_scores}")
print(f"â€¢ Moyenne: {cv_rmse_scores.mean():.2f}")
print(f"â€¢ Ã‰cart-type: {cv_rmse_scores.std():.2f}")

# PrÃ©dictions sur un Ã©chantillon de test
print("ğŸ§ª Test de prÃ©dictions...")

sample_data = X_test.head(5)
sample_predictions = best_model.predict(sample_data)
sample_actual = y_test.head(5)

print("ğŸ“‹ Comparaison prÃ©dictions vs rÃ©alitÃ©:")
for i, (pred, actual) in enumerate(zip(sample_predictions, sample_actual)):
    print(f"  Ã‰chantillon {i+1}: PrÃ©dit={pred:.2f}min, RÃ©el={actual:.2f}min, Erreur={abs(pred-actual):.2f}min")

print("\nğŸ¯ SYNTHÃˆSE DE LA MODÃ‰LISATION")
print("=" * 50)

print(f"\nğŸ“Š Performance du meilleur modÃ¨le ({best_model_name}):")
print(f"â€¢ RMSE: {results[best_model_name]['RMSE']:.2f}")
print(f"â€¢ MAE: {results[best_model_name]['MAE']:.2f}")
print(f"â€¢ RÂ²: {results[best_model_name]['RÂ²']:.3f}")

if results[best_model_name]['RÂ²'] > 0.7:
    print("âœ… Objectif de prÃ©cision (70%) atteint !")
else:
    print("âš ï¸ Objectif de prÃ©cision non atteint, amÃ©lioration nÃ©cessaire.")

print("\nğŸ” FACTEURS PRINCIPAUX IDENTIFIÃ‰S:")
print("â€¢ Analyse des features importantes rÃ©vÃ¨le les variables les plus influentes")
if 'Random Forest' in models:
    print("â€¢ Features importantes :", list(feature_importance.head(3)['feature']))

# Sauvegarde des rÃ©sultats
results_df.to_csv("./results/model_comparison.csv")
if 'Random Forest' in models:
    feature_importance.to_csv("./results/feature_importance.csv")

print("\nğŸ’¾ RÃ©sultats sauvegardÃ©s dans ./results/")
print("âœ… MODÃ‰LISATION TERMINÃ‰E AVEC SUCCÃˆS !")