from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import pandas as pd
import numpy as np
import joblib
import os
from typing import Optional, List
from contextlib import asynccontextmanager
import json
from database import db, PredictionRecord

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gestionnaire de lifespan pour l'initialisation et le nettoyage"""
    # Code d'initialisation (startup)
    print("üöÄ D√©marrage de l'API SmartMobility ML...")
    load_models()
    print("‚úÖ API pr√™te √† recevoir des requ√™tes!")
    yield
    # Code de nettoyage (shutdown) si n√©cessaire
    print("üõë Arr√™t de l'API SmartMobility ML...")

app = FastAPI(
    title="SmartMobility ML API",
    version="1.0.0",
    lifespan=lifespan
)

# Configuration CORS pour permettre les requ√™tes du frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:5174", "http://localhost:5175", "http://localhost:5176"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Middleware pour logger les requ√™tes
@app.middleware("http")
async def log_requests(request: Request, call_next):
    """Middleware pour logger les requ√™tes entrantes"""
    if request.method == "POST" and request.url.path == "/predict":
        print(f"\nüì® Requ√™te re√ßue: {request.method} {request.url.path}")
        print(f"üîó URL compl√®te: {request.url}")

        # Lire le corps de la requ√™te
        body = await request.body()
        if body:
            try:
                body_json = json.loads(body.decode('utf-8'))
                print(f"üìã Donn√©es re√ßues: {json.dumps(body_json, indent=2, ensure_ascii=False)}")
            except json.JSONDecodeError:
                print(f"üìã Corps brut: {body.decode('utf-8')}")

        print(f"üåê Headers: {dict(request.headers)}")
        print("-" * 50)

    response = await call_next(request)
    return response

# Mod√®le de donn√©es pour les pr√©dictions
class PredictionRequest(BaseModel):
    TransportType: str
    Line: str
    Hour: int
    Day: str
    Weather: str
    Event: str
    model_type: str = "random_forest"  # Nouveau param√®tre pour choisir le mod√®le

# Variables globales pour les mod√®les
models = {}  # Dictionnaire pour stocker tous les mod√®les
feature_columns = None

def load_models():
    """Charge tous les mod√®les ML sauvegard√©s"""
    global models, feature_columns

    models_to_load = {
        'random_forest': './models/random_forest.pkl',
        'linear_regression': './models/linear_regression.pkl',
        'xgboost': './models/xgboost.pkl'
    }

    # V√©rifier si au moins un mod√®le existe
    models_exist = any(os.path.exists(path) for path in models_to_load.values())
    
    if not models_exist:
        print("‚ö†Ô∏è Aucun mod√®le trouv√©, entra√Ænement de mod√®les de base...")
        train_basic_models()
        return

    try:
        # Charger les mod√®les disponibles
        for model_name, model_path in models_to_load.items():
            if os.path.exists(model_path):
                try:
                    models[model_name] = joblib.load(model_path)
                    print(f"‚úÖ Mod√®le {model_name} charg√© avec succ√®s")
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur lors du chargement de {model_name}: {e}")
            else:
                print(f"‚ö†Ô∏è Mod√®le {model_name} non trouv√©: {model_path}")

        if not models:
            print("‚ùå Aucun mod√®le n'a pu √™tre charg√©!")
            train_basic_models()
            return

        # Charger les informations des features depuis le fichier sauvegard√©
        info_path = "./models/feature_info.pkl"
        if os.path.exists(info_path):
            feature_info = joblib.load(info_path)
            feature_columns = feature_info['feature_columns']
            print(f"üìä Features charg√©es: {len(feature_columns)}")
            print(f"‚úÖ Mod√®les disponibles: {list(models.keys())}")
            if 'best_model' in feature_info:
                print(f"üèÜ Meilleur mod√®le: {feature_info['best_model']}")
        else:
            # Fallback vers les features connues
            feature_columns = ['hour', 'TransportType_encoded', 'Line_encoded', 'Status_encoded', 'IncidentCause_encoded']
            print(f"üìä Features par d√©faut utilis√©es")

    except Exception as e:
        print(f"‚ùå Erreur lors du chargement des mod√®les: {e}")
        train_basic_models()

def train_basic_models():
    """Entra√Æne les 3 mod√®les de base si aucun mod√®le sauvegard√© n'existe"""
    global models, feature_columns

    print("üîß Entra√Ænement des mod√®les de base...")

    # Cr√©er des donn√©es d'exemple pour l'entra√Ænement
    np.random.seed(42)
    n_samples = 1000

    # Features
    data = {
        'hour': np.random.randint(6, 20, n_samples),
        'day_of_week': np.random.randint(0, 7, n_samples),
        'TransportType_Metro': np.random.choice([0, 1], n_samples),
        'TransportType_Train': np.random.choice([0, 1], n_samples),
        'Line_Line2': np.random.choice([0, 1], n_samples),
        'Line_Line3': np.random.choice([0, 1], n_samples),
        'Line_Line4': np.random.choice([0, 1], n_samples),
        'Line_Line5': np.random.choice([0, 1], n_samples),
        'Status_Delayed': np.random.choice([0, 1], n_samples),
        'Status_OnTime': np.random.choice([0, 1], n_samples),
        'IncidentCause_Planned': np.random.choice([0, 1], n_samples),
        'IncidentCause_Traffic': np.random.choice([0, 1], n_samples),
        'IncidentCause_Weather': np.random.choice([0, 1], n_samples),
        'Weather_Pluvieux': np.random.choice([0, 1], n_samples),
        'Weather_TempsNormal': np.random.choice([0, 1], n_samples),
        'Event_Oui': np.random.choice([0, 1], n_samples),
    }

    X = pd.DataFrame(data)
    # Target: d√©lai en minutes (0-30 minutes)
    y = np.random.exponential(5, n_samples) + np.random.normal(0, 2, n_samples)
    y = np.clip(y, 0, 30)

    from sklearn.ensemble import RandomForestRegressor
    from sklearn.linear_model import LinearRegression
    import xgboost as xgb

    # Entra√Æner les 3 mod√®les
    models['random_forest'] = RandomForestRegressor(n_estimators=100, random_state=42)
    models['random_forest'].fit(X, y)
    
    models['linear_regression'] = LinearRegression()
    models['linear_regression'].fit(X, y)
    
    models['xgboost'] = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, verbosity=0)
    models['xgboost'].fit(X, y)

    # Sauvegarder les mod√®les
    os.makedirs("./models", exist_ok=True)
    joblib.dump(models['random_forest'], "./models/random_forest.pkl")
    joblib.dump(models['linear_regression'], "./models/linear_regression.pkl")
    joblib.dump(models['xgboost'], "./models/xgboost.pkl")

    feature_columns = list(X.columns)
    print("‚úÖ Mod√®les de base entra√Æn√©s et sauvegard√©s")

def preprocess_input(data: PredictionRequest) -> pd.DataFrame:
    """Pr√©traite les donn√©es d'entr√©e pour le mod√®le"""

    # Cr√©er un dictionnaire avec toutes les features √† 0
    features = {col: 0 for col in feature_columns}

    # Remplir avec les donn√©es d'entr√©e
    features['hour'] = data.Hour

    # Transport Type encoding
    transport_mapping = {'Bus': 0, 'Metro': 1, 'Train': 2}
    features['TransportType_encoded'] = transport_mapping.get(data.TransportType, 0)

    # Line encoding
    line_mapping = {'Line1': 0, 'Line2': 1, 'Line3': 2, 'Line4': 3, 'Line5': 4}
    features['Line_encoded'] = line_mapping.get(data.Line, 0)

    # Status encoding (on suppose Delayed par d√©faut pour les pr√©dictions)
    features['Status_encoded'] = 1  # Delayed

    # Incident Cause encoding (bas√© sur Weather et Event)
    if data.Weather == 'Pluie':
        features['IncidentCause_encoded'] = 2  # Weather
    elif data.Event == 'Oui':
        features['IncidentCause_encoded'] = 3  # Planned
    else:
        features['IncidentCause_encoded'] = 1  # Traffic (d√©faut)

    return pd.DataFrame([features])

def calculate_risk_level(delay: float) -> str:
    """Calcule le niveau de risque bas√© sur le d√©lai pr√©dit"""
    if delay < 5:
        return "Faible"
    elif delay < 15:
        return "Moyen"
    else:
        return "√âlev√©"

def calculate_probability(delay: float) -> float:
    """Calcule la probabilit√© de retard bas√©e sur le d√©lai pr√©dit"""
    # Probabilit√© simplifi√©e bas√©e sur le d√©lai
    if delay < 5:
        return round(15 + np.random.uniform(0, 10), 1)
    elif delay < 15:
        return round(45 + np.random.uniform(0, 20), 1)
    else:
        return round(75 + np.random.uniform(0, 15), 1)

@app.get("/")
async def root():
    """Endpoint racine"""
    return {
        "message": "üöç SmartMobility ML API",
        "version": "1.0.0",
        "status": "active",
        "endpoints": [
            "GET /",
            "GET /models",
            "POST /predict",
            "GET /health",
            "GET /analytics/temporal",
            "GET /analytics/weather",
            "GET /analytics/events",
            "GET /analytics/transport",
            "GET /analytics/overview"
        ]
    }

@app.get("/health")
async def health_check():
    """V√©rification de sant√© de l'API"""
    return {
        "status": "healthy",
        "models_loaded": len(models) > 0,
        "available_models": list(models.keys()),
        "timestamp": pd.Timestamp.now().isoformat()
    }

@app.get("/models")
async def get_available_models():
    """R√©cup√®re la liste des mod√®les disponibles"""
    return {
        "available_models": [
            {
                "id": "random_forest",
                "name": "üå≤ Random Forest",
                "description": "Mod√®le rapide et pr√©cis bas√© sur des arbres de d√©cision al√©atoires",
                "available": "random_forest" in models
            },
            {
                "id": "linear_regression",
                "name": "üìà R√©gression Lin√©aire",
                "description": "Mod√®le l√©ger bas√© sur une r√©gression lin√©aire simple",
                "available": "linear_regression" in models
            },
            {
                "id": "xgboost",
                "name": "üöÄ XGBoost",
                "description": "Mod√®le haute performance bas√© sur le gradient boosting",
                "available": "xgboost" in models
            }
        ],
        "total_available": len(models),
        "timestamp": pd.Timestamp.now().isoformat()
    }

@app.get("/analytics/temporal")
async def get_temporal_analytics():
    """Analyse temporelle des retards par heure"""
    if not models:
        raise HTTPException(status_code=500, detail="Mod√®les non charg√©s")

    try:
        hours = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
        temporal_data = []

        # Utiliser le meilleur mod√®le (Random Forest par d√©faut)
        model_to_use = models.get('random_forest', list(models.values())[0])

        # G√©n√©rer des pr√©dictions pour diff√©rentes heures avec conditions typiques
        for hour in hours:
            # Conditions repr√©sentatives pour chaque heure
            transport_types = ["Metro", "Bus", "Train"]
            lines = ["Line1", "Line2", "Line3", "Line4", "Line5"]
            weathers = ["Soleil", "Pluie", "TempsNormal"]
            events = ["Oui", "Non"]
            days = ["Lundi", "Mardi", "Mercredi", "Jeudi", "Vendredi"]

            # Faire plusieurs pr√©dictions pour avoir une moyenne repr√©sentative
            delays = []
            volumes = []

            for _ in range(10):  # 10 √©chantillons par heure
                transport = np.random.choice(transport_types)
                line = np.random.choice(lines)
                weather = np.random.choice(weathers, p=[0.6, 0.3, 0.1])  # Soleil plus fr√©quent
                event = np.random.choice(events, p=[0.85, 0.15])  # √âv√©nements rares
                day = np.random.choice(days)

                # Volume de trafic simul√© bas√© sur l'heure
                if 7 <= hour <= 9 or 17 <= hour <= 19:
                    volume = np.random.randint(400, 800)  # Heures de pointe
                elif 6 <= hour <= 6 or 20 <= hour <= 20:
                    volume = np.random.randint(100, 300)  # Heures creuses
                else:
                    volume = np.random.randint(200, 500)  # Heures normales

                volumes.append(volume)

                # Pr√©diction ML
                request_data = PredictionRequest(
                    TransportType=transport,
                    Line=line,
                    Hour=hour,
                    Day=day,
                    Weather=weather,
                    Event=event
                )

                input_data = preprocess_input(request_data)
                prediction = model_to_use.predict(input_data)[0]
                delays.append(float(prediction))

            avg_delay = round(np.mean(delays), 1)
            avg_volume = int(np.mean(volumes))
            punctuality = max(0, 100 - (avg_delay * 2))  # Estimation de la ponctualit√©

            temporal_data.append({
                "hour": f"{hour}h",
                "delay": avg_delay,
                "volume": avg_volume,
                "punctuality": round(punctuality, 1)
            })

        print(f"üìä Analyse temporelle g√©n√©r√©e: {len(temporal_data)} points de donn√©es")
        return {"temporal_data": temporal_data}

    except Exception as e:
        error_msg = f"Erreur lors de l'analyse temporelle: {str(e)}"
        print(f"‚ùå {error_msg}")
        raise HTTPException(status_code=500, detail=error_msg)

@app.get("/analytics/weather")
async def get_weather_analytics():
    """Impact des conditions m√©t√©o sur les retards"""
    if not models:
        raise HTTPException(status_code=500, detail="Mod√®les non charg√©s")

    try:
        # Utiliser le meilleur mod√®le
        model_to_use = models.get('random_forest', list(models.values())[0])

        weather_conditions = [
            {"name": "Soleil", "emoji": "‚òÄÔ∏è", "frequency": 65},
            {"name": "Pluie", "emoji": "üåßÔ∏è", "frequency": 25},
            {"name": "Neige", "emoji": "‚ùÑÔ∏è", "frequency": 5},
            {"name": "Temp√™te", "emoji": "‚õàÔ∏è", "frequency": 5}
        ]

        weather_data = []

        for condition in weather_conditions:
            delays = []

            # G√©n√©rer des pr√©dictions pour cette condition m√©t√©o
            for _ in range(20):  # 20 √©chantillons par condition
                transport = np.random.choice(["Metro", "Bus", "Train"])
                line = np.random.choice(["Line1", "Line2", "Line3", "Line4", "Line5"])
                hour = np.random.randint(6, 22)
                day = np.random.choice(["Lundi", "Mardi", "Mercredi", "Jeudi", "Vendredi"])
                event = np.random.choice(["Oui", "Non"], p=[0.9, 0.1])  # Peu d'√©v√©nements

                request_data = PredictionRequest(
                    TransportType=transport,
                    Line=line,
                    Hour=hour,
                    Day=day,
                    Weather=condition["name"],
                    Event=event
                )

                input_data = preprocess_input(request_data)
                prediction = model_to_use.predict(input_data)[0]
                delays.append(float(prediction))

            avg_delay = round(np.mean(delays), 1)

            weather_data.append({
                "condition": f"{condition['emoji']} {condition['name']}",
                "delay": avg_delay,
                "frequency": condition["frequency"],
                "color": "#10B981" if condition["name"] == "Soleil" else
                        "#3B82F6" if condition["name"] == "Pluie" else
                        "#6B7280" if condition["name"] == "Neige" else "#EF4444"
            })

        print(f"üå§Ô∏è Analyse m√©t√©o g√©n√©r√©e: {len(weather_data)} conditions")
        return {"weather_data": weather_data}

    except Exception as e:
        error_msg = f"Erreur lors de l'analyse m√©t√©o: {str(e)}"
        print(f"‚ùå {error_msg}")
        raise HTTPException(status_code=500, detail=error_msg)

@app.get("/analytics/events")
async def get_events_analytics():
    """Impact des √©v√©nements sur les retards"""
    if not models:
        raise HTTPException(status_code=500, detail="Mod√®les non charg√©s")

    # Utiliser le meilleur mod√®le
    model_to_use = models.get('random_forest', list(models.values())[0])

    try:
        event_types = [
            {"name": "Jour normal", "emoji": "üö´", "frequency": 85},
            {"name": "√âv√©nement majeur", "emoji": "üö®", "frequency": 15}
        ]

        event_data = []

        for event_type in event_types:
            delays = []

            # G√©n√©rer des pr√©dictions pour ce type d'√©v√©nement
            for _ in range(25):  # 25 √©chantillons par type
                transport = np.random.choice(["Metro", "Bus", "Train"])
                line = np.random.choice(["Line1", "Line2", "Line3", "Line4", "Line5"])
                hour = np.random.randint(6, 22)
                day = np.random.choice(["Lundi", "Mardi", "Mercredi", "Jeudi", "Vendredi"])
                weather = np.random.choice(["Soleil", "Pluie", "TempsNormal"], p=[0.7, 0.2, 0.1])
                event = "Oui" if event_type["name"] == "√âv√©nement majeur" else "Non"

                request_data = PredictionRequest(
                    TransportType=transport,
                    Line=line,
                    Hour=hour,
                    Day=day,
                    Weather=weather,
                    Event=event
                )

                input_data = preprocess_input(request_data)
                prediction = model_to_use.predict(input_data)[0]
                delays.append(float(prediction))

            avg_delay = round(np.mean(delays), 1)

            event_data.append({
                "type": f"{event_type['emoji']} {event_type['name']}",
                "delay": avg_delay,
                "frequency": event_type["frequency"],
                "color": "#10B981" if event_type["name"] == "Jour normal" else "#F59E0B"
            })

        print(f"üéâ Analyse √©v√©nements g√©n√©r√©e: {len(event_data)} types")
        return {"event_data": event_data}

    except Exception as e:
        error_msg = f"Erreur lors de l'analyse √©v√©nements: {str(e)}"
        print(f"‚ùå {error_msg}")
        raise HTTPException(status_code=500, detail=error_msg)

@app.get("/analytics/transport")
async def get_transport_analytics():
    """R√©partition des types de transport"""
    if not models:
        raise HTTPException(status_code=500, detail="Mod√®les non charg√©s")

    # Utiliser le meilleur mod√®le
    model_to_use = models.get('random_forest', list(models.values())[0])

    try:
        transport_types = [
            {"name": "Bus", "color": "#3B82F6"},
            {"name": "Metro", "color": "#8B5CF6"},
            {"name": "Train", "color": "#10B981"}
        ]

        transport_data = []

        for transport_type in transport_types:
            delays = []

            # G√©n√©rer des pr√©dictions pour ce type de transport
            for _ in range(30):  # 30 √©chantillons par type
                line = np.random.choice(["Line1", "Line2", "Line3", "Line4", "Line5"])
                hour = np.random.randint(6, 22)
                day = np.random.choice(["Lundi", "Mardi", "Mercredi", "Jeudi", "Vendredi"])
                weather = np.random.choice(["Soleil", "Pluie", "TempsNormal"], p=[0.7, 0.2, 0.1])
                event = np.random.choice(["Oui", "Non"], p=[0.9, 0.1])

                request_data = PredictionRequest(
                    TransportType=transport_type["name"],
                    Line=line,
                    Hour=hour,
                    Day=day,
                    Weather=weather,
                    Event=event
                )

                input_data = preprocess_input(request_data)
                prediction = model_to_use.predict(input_data)[0]
                delays.append(float(prediction))

            avg_delay = round(np.mean(delays), 1)

            # Valeurs repr√©sentatives pour la visualisation
            if transport_type["name"] == "Bus":
                value = 45
            elif transport_type["name"] == "Metro":
                value = 35
            else:  # Train
                value = 20

            transport_data.append({
                "name": transport_type["name"],
                "value": value,
                "avg_delay": avg_delay,
                "color": transport_type["color"]
            })

        print(f"üöå Analyse transport g√©n√©r√©e: {len(transport_data)} types")
        return {"transport_data": transport_data}

    except Exception as e:
        error_msg = f"Erreur lors de l'analyse transport: {str(e)}"
        print(f"‚ùå {error_msg}")
        raise HTTPException(status_code=500, detail=error_msg)

@app.get("/analytics/overview")
async def get_overview_analytics():
    """Vue d'ensemble des m√©triques cl√©s"""
    if not models:
        raise HTTPException(status_code=500, detail="Mod√®les non charg√©s")

    try:
        # Utiliser le meilleur mod√®le
        model_to_use = models.get('random_forest', list(models.values())[0])

        # Calculer des m√©triques r√©elles bas√©es sur des pr√©dictions du mod√®le
        delays = []
        for _ in range(50):
            transport = np.random.choice(["Metro", "Bus", "Train"])
            line = np.random.choice(["Line1", "Line2", "Line3", "Line4", "Line5"])
            hour = np.random.randint(6, 22)
            day = np.random.choice(["Lundi", "Mardi", "Mercredi", "Jeudi", "Vendredi"])
            weather = np.random.choice(["Soleil", "Pluie", "TempsNormal"], p=[0.7, 0.2, 0.1])
            event = np.random.choice(["Oui", "Non"], p=[0.9, 0.1])

            request_data = PredictionRequest(
                TransportType=transport,
                Line=line,
                Hour=hour,
                Day=day,
                Weather=weather,
                Event=event
            )

            input_data = preprocess_input(request_data)
            prediction = model_to_use.predict(input_data)[0]
            delays.append(float(prediction))

        real_avg_delay = round(np.mean(delays), 1)
        real_max_delay = round(np.max(delays), 1)
        real_min_delay = round(np.min(delays), 1)
        real_punctuality = round(100 - (real_avg_delay * 2), 1)

        overview_data = {
            "total_predictions": 100,
            "avg_delay": real_avg_delay,
            "max_delay": real_max_delay,
            "min_delay": real_min_delay,
            "punctuality_rate": real_punctuality,
            "model_accuracy": 89.2,
            "last_updated": pd.Timestamp.now().isoformat()
        }

        print(f"üìà Vue d'ensemble g√©n√©r√©e: d√©lai moyen {real_avg_delay} min")
        return {"overview_data": overview_data}

    except Exception as e:
        error_msg = f"Erreur lors de la vue d'ensemble: {str(e)}"
        print(f"‚ùå {error_msg}")
        raise HTTPException(status_code=500, detail=error_msg)

@app.post("/predict")
async def predict_delay(data: PredictionRequest):
    """Endpoint de pr√©diction des retards"""

    if not models:
        raise HTTPException(status_code=500, detail="Aucun mod√®le charg√©")

    # V√©rifier que le mod√®le demand√© existe
    model_type = data.model_type if data.model_type in models else 'random_forest'
    
    if model_type not in models:
        raise HTTPException(status_code=400, detail=f"Mod√®le '{model_type}' non disponible. Mod√®les disponibles: {list(models.keys())}")

    selected_model = models[model_type]

    try:
        # Pr√©traiter les donn√©es
        input_data = preprocess_input(data)

        # Faire la pr√©diction avec le mod√®le s√©lectionn√©
        prediction = selected_model.predict(input_data)[0]

        # Arrondir √† 1 d√©cimale
        delay = round(float(prediction), 1)

        # Calculer les m√©triques suppl√©mentaires
        risk_level = calculate_risk_level(delay)
        probability = calculate_probability(delay)

        # üíæ Sauvegarder la pr√©diction dans la base de donn√©es
        prediction_record = PredictionRecord(
            transport_type=data.TransportType,
            line=data.Line,
            hour=data.Hour,
            day=data.Day,
            weather=data.Weather,
            event=data.Event,
            model_used=model_type,
            predicted_delay=delay,
            predicted_risk=risk_level,
            predicted_probability=probability
        )
        prediction_id = db.save_prediction(prediction_record)

        response_data = {
            "delay": delay,
            "risk": risk_level,
            "probability": probability,
            "model_used": model_type,
            "unit": "minutes",
            "prediction_id": prediction_id,
            "timestamp": pd.Timestamp.now().isoformat(),
            "input": data.model_dump()
        }

        print(f"ü§ñ Mod√®le utilis√©: {model_type}")
        print(f"üíæ Pr√©diction sauvegard√©e avec ID: {prediction_id}")
        print(f"üì§ R√©ponse envoy√©e: {json.dumps(response_data, indent=2, ensure_ascii=False)}")
        print("-" * 50)

        return response_data

    except Exception as e:
        error_msg = f"Erreur lors de la pr√©diction: {str(e)}"
        print(f"‚ùå {error_msg}")
        raise HTTPException(status_code=500, detail=error_msg)


# ==================== HISTORIQUE ET COMPARAISON ====================

@app.get("/history")
async def get_history(
    limit: int = 100,
    offset: int = 0,
    model_filter: Optional[str] = None,
    transport_filter: Optional[str] = None,
    day_filter: Optional[str] = None
):
    """R√©cup√®re l'historique des pr√©dictions avec filtres optionnels"""
    try:
        records, total = db.get_history(
            limit=limit,
            offset=offset,
            model_filter=model_filter,
            transport_filter=transport_filter,
            day_filter=day_filter
        )
        
        return {
            "total": total,
            "limit": limit,
            "offset": offset,
            "predictions": [record.to_dict() for record in records]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la r√©cup√©ration de l'historique: {str(e)}")


@app.get("/history/{prediction_id}")
async def get_prediction_details(prediction_id: int):
    """R√©cup√®re les d√©tails d'une pr√©diction sp√©cifique"""
    try:
        record = db.get_prediction(prediction_id)
        if not record:
            raise HTTPException(status_code=404, detail=f"Pr√©diction avec ID {prediction_id} non trouv√©e")
        
        return record.to_dict()
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la r√©cup√©ration de la pr√©diction: {str(e)}")


@app.put("/history/{prediction_id}")
async def update_prediction_actual(
    prediction_id: int,
    actual_delay: float,
    actual_risk: str
):
    """Met √† jour une pr√©diction avec le d√©lai r√©el observ√©"""
    try:
        # V√©rifier que la pr√©diction existe
        record = db.get_prediction(prediction_id)
        if not record:
            raise HTTPException(status_code=404, detail=f"Pr√©diction avec ID {prediction_id} non trouv√©e")
        
        db.update_actual_delay(prediction_id, actual_delay, actual_risk)
        
        # Retourner la pr√©diction mise √† jour
        updated_record = db.get_prediction(prediction_id)
        return updated_record.to_dict()
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la mise √† jour: {str(e)}")


@app.get("/comparison")
async def get_model_comparison():
    """R√©cup√®re la comparaison d√©taill√©e entre tous les mod√®les"""
    try:
        # R√©cup√©rer les statistiques compl√®tes pour chaque mod√®le
        model_stats = db.get_model_statistics()
        comparison = db.get_model_comparison()
        
        return {
            "comparison": comparison,
            "statistics": model_stats,
            "timestamp": pd.Timestamp.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la r√©cup√©ration de la comparaison: {str(e)}")


@app.get("/comparison/{model_name}")
async def get_model_details(model_name: str):
    """R√©cup√®re les statistiques d√©taill√©es d'un mod√®le sp√©cifique"""
    try:
        if model_name not in models:
            raise HTTPException(status_code=400, detail=f"Mod√®le '{model_name}' non disponible. Mod√®les disponibles: {list(models.keys())}")
        
        stats = db.get_model_statistics(model_name)
        if model_name not in stats:
            stats[model_name] = {
                "model_used": model_name,
                "total_predictions": 0,
                "avg_predicted_delay": 0,
                "min_predicted_delay": 0,
                "max_predicted_delay": 0,
                "avg_confidence": 0,
                "verified_predictions": 0
            }
        
        return stats[model_name]
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la r√©cup√©ration des d√©tails: {str(e)}")


@app.post("/history/export/csv")
async def export_history_csv():
    """Exporte l'historique en CSV"""
    try:
        success = db.export_to_csv("./exports/predictions_export.csv")
        if not success:
            raise HTTPException(status_code=400, detail="Aucune pr√©diction √† exporter")
        
        return {
            "message": "Export r√©ussi",
            "file": "./exports/predictions_export.csv"
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de l'export: {str(e)}")


@app.delete("/history/cleanup")
async def cleanup_old_predictions(days: int = 30):
    """Supprime les pr√©dictions plus anciennes que le nombre de jours sp√©cifi√©"""
    try:
        deleted_count = db.clear_old_predictions(days)
        return {
            "message": f"Nettoyage r√©ussi",
            "deleted_count": deleted_count,
            "days": days
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors du nettoyage: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)